#version 450
#extension GL_GOOGLE_include_directive : require
#extension GL_ARB_gpu_shader_int64 : require
#extension GL_EXT_debug_printf : enable
layout(local_size_x = 128, local_size_y = 1, local_size_z = 1) in;

#include "common_variables.glsl"
#include "common_random.glsl"
#include "common_brickmap.glsl"
#include "common_raytrace.glsl"

layout (std430, set = 0, binding = 0) buffer ray_buffer
{
	ray rays[]; 
};

layout (std430, set = 1, binding = 0) buffer globals_buffer
{
    uint start_position;
    uint primary_ray_count;
    uint shadow_ray_count;
    uint ray_number_primary;
    uint ray_number_extend;
    uint ray_number_shade;
    uint ray_number_connect;
    uint ray_queue_buffer_size;
};

layout (set = 2, binding = 0) buffer blit_buffer
{
    vec4 colors[];
};

layout (push_constant) uniform push_constants
{
    // Ray Gen Properties
    uint frame;
    uint render_width;
    uint render_height;
    uint pad_0;

    // Camera Properties
    vec4 camera_direction;
    vec4 camera_up;
    vec4 camera_right;
    vec4 camera_position;
    float focal_distance;
    float lens_radius;
    vec2 sun_position;
};

vec2 concentric_sample_disk( vec2 u )
{
	//Map from [0,1] to [-1,1]
	vec2 u_offset = 2.f * u - vec2( 1, 1 );

	// Handle degeneracy at the origin
	if ( u_offset.x == 0 && u_offset.y == 0 )
		return vec2( 0, 0 );

	// Apply concentric mapping to point
	float theta, r;
	if ( abs(u_offset.x) > abs(u_offset.y) )
    {
		r = u_offset.x;
		theta = PI / 4 * ( u_offset.y / u_offset.x );
	}
    else
    {
		r = u_offset.y;
		theta = PI / 2 - PI / 4 * ( u_offset.x / u_offset.y );
	}

	return r * vec2( cos( theta ), sin( theta ) );
}

void main()
{
    uint index = atomicAdd( ray_number_primary, 1u );

    // Buffer already includes rays generated by previous "shade" step (primary_ray_count).
	uint ray_index = index + primary_ray_count;
	if ( ray_index > ray_queue_buffer_size - 1 )
    {
		return;
	}

	uint seed = (frame * 147565741) * 720898027 * index;

	uint x =   ( start_position + index ) % render_width;
	uint y = ( ( start_position + index ) / render_width  ) % render_height;

    // Get random stratified points inside pixel.
    vec2 sample2d = random_2d_stratified_sample( seed );
    float rand_point_pixel_x = x - sample2d.x;
    float rand_point_pixel_y = y - sample2d.y;

	float normalized_i = ( rand_point_pixel_x / float(render_width) ) - 0.5f;
	float normalized_j = ( ( render_height - rand_point_pixel_y ) / float(render_height) ) - 0.5f;

    // Normal direction which we would compute even without DoF...
    vec3 dir_to_focal_plane = camera_direction.xyz + normalized_i * camera_right.xyz + normalized_j * camera_up.xyz;
    dir_to_focal_plane = normalize( dir_to_focal_plane );

    // Get the convergence point which is at focal_distance.
    int ImGui_slider_hack = 500;
    float lr = lens_radius;
    lr = 0;
    vec3 convergence_point = camera_position.xyz + focal_distance * ImGui_slider_hack * dir_to_focal_plane;

    vec2 lens_sample = vec2( random_float( seed ), random_float( seed ) );
    vec2 lens = lr * concentric_sample_disk( lens_sample );
    vec3 ray_origin = camera_position.xyz + camera_right.xyz * lens.x + camera_up.xyz * lens.y;
    vec3 ray_direction = normalize( convergence_point - ray_origin );

	ray_direction.x = abs( ray_direction.x ) > epsilon ? ray_direction.x : ( ray_direction.x >= 0 ? epsilon : -epsilon );
	ray_direction.y = abs( ray_direction.y ) > epsilon ? ray_direction.y : ( ray_direction.y >= 0 ? epsilon : -epsilon );
    ray_direction.z = abs( ray_direction.z ) > epsilon ? ray_direction.z : ( ray_direction.z >= 0 ? epsilon : -epsilon );

    uint pixel_index = y * render_width + x;

    rays[ray_index] = ray( vec4( ray_origin, 1 ), vec4( ray_direction, 1 ), vec4( 1.f ), vec4( 0.f ), 0.f, 0, 0, pixel_index );

    // tmp
    colors[pixel_index] = vec4( 0.4, 0.2, 0.8, 1 );
}
